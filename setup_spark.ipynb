{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".h1_cell, .just_text {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-family: \"Times New Roman\", Georgia, Serif;\n",
    "    font-size: 125%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    text-indent: 25px;\n",
    "    background-color: #fbfbea;\n",
    "    padding: 10px;\n",
    "}\n",
    ".code_block {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-size: 75%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    #text-indent: 25px;\n",
    "    #background-color: #fbfbea;\n",
    "    padding: 5px;\n",
    "}\n",
    "\n",
    "hr { \n",
    "    display: block;\n",
    "    margin-top: 0.5em;\n",
    "    margin-bottom: 0.5em;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    border-style: inset;\n",
    "    border-width: 2px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Download and Installation\n",
    "</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Download the spark tarball in the current directory. The URL is one of many mirrors listed on spark's official website.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_url = \"http://apache.osuosl.org/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz\"\n",
    "r = requests.get(spark_url, stream=True)\n",
    "filename = spark_url.rsplit('/')[-1]\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Extract the spark tarball in the 'spark/' directory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call('mkdir spark'.split(' '))\n",
    "subprocess.call('tar -xf spark-2.3.0-bin-hadoop2.7.tgz -C spark --strip-components 1'.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Add spark_home environment variable.\n",
    "<p>\n",
    "Add spark_home + '/bin' to run a pyspark console.\n",
    "<p>\n",
    "Add spark_home + '/python*' to environment to import pyspark.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = os.environ['HOME'] + '/spark'\n",
    "os.environ['PATH'] += ':' + os.environ['SPARK_HOME'] + '/bin'\n",
    "sys.path.append(os.environ['SPARK_HOME'] + '/python')\n",
    "sys.path.append(os.environ['SPARK_HOME'] + '/python/lib/py4j-0.10.6-src.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Write the names of the slave nodes in the cluster. This script currently assumes the master machine is blue0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines = [\"blue1\", \"blue3\"]\n",
    "content = \"\\n\".join(machines)\n",
    "with open(os.environ['SPARK_HOME'] + \"/conf/slaves\", 'w') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "We now need to do the same exact thing on all the slave nodes. We will:\n",
    "<ul>\n",
    "<li>\n",
    "Convert this notebook to a python file.\n",
    "<li>\n",
    "Delete the lines after the comment in the code below.\n",
    "<li>\n",
    "Run the editted python script on each slave node.\n",
    "</ul>\n",
    "<p>\n",
    "Note: These nodes must have password-less ssh tunneling configured.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this ipython notebook to python script\n",
    "!jupyter nbconvert --to=python setup_spark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = open('setup_spark.py', 'r')\n",
    "lines = read_file.readlines()\n",
    "read_file.close()\n",
    "with open('setup_spark.py', 'w') as f:\n",
    "    i = 0\n",
    "    while i < len(lines) and lines[i].strip() != '# Convert this ipython notebook to python script':\n",
    "        f.write(lines[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "This will take awhile. For each node, the script is downloading spark, extracting the package and configuring the environment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh blue1 python < setup_spark.py\n",
    "!ssh blue3 python < setup_spark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Using PySpark\n",
    "</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Start the cluster.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run start-all.sh\n",
    "subprocess.call(os.environ['SPARK_HOME'] + \"/sbin/start-all.sh\", env=os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "This is where most other programs regarding this project will start.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://blue0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://blue0:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x70431230>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(SparkContext(master='spark://blue0:7077'))\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Lets generate some semi-random data and run a Spark K-Means implementation on it. We'll create a 2D array with 4 centers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|                  A|                  B|\n",
      "+-------------------+-------------------+\n",
      "|0.37934741961671314|0.19842292770414172|\n",
      "| 0.4827234474797606| 0.8368192843182927|\n",
      "| 0.7645647616824591| 0.2901033322963689|\n",
      "|0.04517736175807846| 0.2516191581625483|\n",
      "| 0.0997401767803513| 0.8537358668875344|\n",
      "+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 clusters\n",
    "from random import random, shuffle\n",
    "\n",
    "upper_left = [[random()*0.5, random()*0.5 + 0.5] for _ in range(2500)]\n",
    "upper_right = [[random()*0.5 + 0.5 for _ in range(2)] for _ in range(2500)]\n",
    "bottom_left = [[random()*0.5 for _ in range(2)] for _ in range(2500)]\n",
    "bottom_right = [[random()*.5 + 0.5, random()*0.5] for _ in range(2500)]\n",
    "\n",
    "matrix = upper_left + upper_right + bottom_left + bottom_right\n",
    "shuffle(matrix)\n",
    "\n",
    "data = spark.createDataFrame(matrix, schema=[\"A\", \"B\"])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|                  A|                  B|            features|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|0.37934741961671314|0.19842292770414172|[0.37934741961671...|\n",
      "| 0.4827234474797606| 0.8368192843182927|[0.48272344747976...|\n",
      "| 0.7645647616824591| 0.2901033322963689|[0.76456476168245...|\n",
      "|0.04517736175807846| 0.2516191581625483|[0.04517736175807...|\n",
      "| 0.0997401767803513| 0.8537358668875344|[0.09974017678035...|\n",
      "+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vdf = VectorAssembler(inputCols=data.columns, outputCol=\"features\").transform(data)\n",
    "vdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 416.826660058\n",
      "Centers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.26453331,  0.23473974]),\n",
       " array([ 0.23673167,  0.74518827]),\n",
       " array([ 0.7365823 ,  0.74851205]),\n",
       " array([ 0.76313915,  0.25215131])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(k=4, maxIter=10, initMode=\"random\")\n",
    "model = kmeans.fit(vdf)\n",
    "\n",
    "wssse = model.computeCost(vdf)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "print(\"Centers:\")\n",
    "model.clusterCenters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "You can compare this to a python-only single-machine k-means to get an idea of performance gain.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>\n",
    "Latent Semantic Analysis\n",
    "</center>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "We can look at all the words in a tweet dataset and determine which words may be related to each other, usually by topic.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> @user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> @user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td>                               bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> #model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td>            factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  @user when a father is dysfunctional and is so...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark doesn't do csv files very well, so we'll read the data into pandas\n",
    "# Then we can pass it to spark\n",
    "if(True):  # if on raspberry pi, change if otherwise\n",
    "    subprocess.call('sudo apt-get install python-pandas'.split(' '))\n",
    "else:\n",
    "    subprocess.call('pip install pandas')\n",
    "\n",
    "import pandas as pd\n",
    "tweets = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1tw90jUqTQoRt-RNOqNWronMN46y7dxb2ciQwj1YFsTo/export?format=csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0]['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "We need to take each tweet, break it down into words and remove any unuseful words (stopwords)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: six in /usr/lib/python2.7/dist-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "[nltk_data] Downloading package stopwords to /home/pi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from string import punctuation\n",
    "\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "download('stopwords')\n",
    "swords = stopwords.words('english')\n",
    "\n",
    "def sentence_wrangler(sentence):\n",
    "    word_list = word_punct_tokenizer.tokenize(sentence.lower())\n",
    "    removed_words = []\n",
    "    result = []\n",
    "    for word in word_list:\n",
    "        if word in swords:\n",
    "            removed_words.append(word)\n",
    "            continue\n",
    "        check = False\n",
    "        for char in word:\n",
    "            if char in punctuation:\n",
    "                check = True\n",
    "                removed_words.append(word)\n",
    "                break\n",
    "        if not check: result.append(word)\n",
    "      \n",
    "    return result, removed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Create a set of all unique words. Then represent each tweet as a RowVector of words.\n",
    "<p>\n",
    "For example, the vector representing \"Clippers down 2 points at the second half #NBAFinals\" would have a 1 in each of the columns of the words in the tweet.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['selfish', 'kids', 'run', 'father', 'drags', 'user', 'dysfunctional', 'dysfunction'])\n"
     ]
    }
   ],
   "source": [
    "# Get tweets with no special characters (ascii)\n",
    "bag = set()\n",
    "sentences = []\n",
    "for i in range(len(tweets.index[:100])):\n",
    "    t = tweets.iloc[i]['tweet']\n",
    "    try:\n",
    "        t.encode('ascii')\n",
    "        words = set(sentence_wrangler(t)[0])\n",
    "        for word in words:\n",
    "            if word not in bag:\n",
    "                bag.add(word)\n",
    "        sentences.append(words)\n",
    "    except UnicodeDecodeError:\n",
    "        pass\n",
    "bag = frozenset(bag)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop</th>\n",
       "      <th>shot</th>\n",
       "      <th>show</th>\n",
       "      <th>tells</th>\n",
       "      <th>probe</th>\n",
       "      <th>ica16</th>\n",
       "      <th>leads</th>\n",
       "      <th>basilicabotanica</th>\n",
       "      <th>go</th>\n",
       "      <th>21st</th>\n",
       "      <th>...</th>\n",
       "      <th>hu</th>\n",
       "      <th>weekend</th>\n",
       "      <th>forever</th>\n",
       "      <th>calls</th>\n",
       "      <th>wife</th>\n",
       "      <th>sometimes</th>\n",
       "      <th>gr8</th>\n",
       "      <th>points</th>\n",
       "      <th>leak</th>\n",
       "      <th>personalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop  shot  show  tells  probe  ica16  leads  basilicabotanica  go  21st  \\\n",
       "0     0     0     0      0      0      0      0                 0   0     0   \n",
       "1     0     0     0      0      0      0      0                 0   0     0   \n",
       "2     0     0     0      0      0      0      0                 0   0     0   \n",
       "3     0     0     0      0      0      0      0                 0   0     0   \n",
       "4     0     0     0      0      0      0      0                 0   0     0   \n",
       "\n",
       "   ...   hu  weekend  forever  calls  wife  sometimes  gr8  points  leak  \\\n",
       "0  ...    0        0        0      0     0          0    0       0     0   \n",
       "1  ...    0        0        0      0     0          0    0       0     0   \n",
       "2  ...    0        0        0      0     0          0    0       0     0   \n",
       "3  ...    0        0        0      0     0          0    0       0     0   \n",
       "4  ...    0        0        0      0     0          0    0       0     0   \n",
       "\n",
       "   personalised  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 422 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = list(bag)\n",
    "occur_matrix = pd.DataFrame(columns=all_words)\n",
    "zeros = [0]*len(bag)\n",
    "for sentence in sentences:\n",
    "    occur_matrix = occur_matrix.append(pd.DataFrame([zeros], columns=all_words), ignore_index=True)\n",
    "    for word in sentence:\n",
    "        occur_matrix.loc[len(occur_matrix.index)-1, word] = 1\n",
    "occur_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now create a co-occurence matrix to represent how many times 2 words appear together in the same dataset. Multiply the occurence matrix by its transpose to get this matrix.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop</th>\n",
       "      <th>shot</th>\n",
       "      <th>show</th>\n",
       "      <th>tells</th>\n",
       "      <th>probe</th>\n",
       "      <th>ica16</th>\n",
       "      <th>leads</th>\n",
       "      <th>basilicabotanica</th>\n",
       "      <th>go</th>\n",
       "      <th>21st</th>\n",
       "      <th>...</th>\n",
       "      <th>hu</th>\n",
       "      <th>weekend</th>\n",
       "      <th>forever</th>\n",
       "      <th>calls</th>\n",
       "      <th>wife</th>\n",
       "      <th>sometimes</th>\n",
       "      <th>gr8</th>\n",
       "      <th>points</th>\n",
       "      <th>leak</th>\n",
       "      <th>personalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shop</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shot</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tells</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probe</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       shop  shot  show  tells  probe  ica16  leads  basilicabotanica  go  \\\n",
       "shop      0     0     0      0      0      0      0                 0   0   \n",
       "shot      0     0     0      0      0      0      0                 0   0   \n",
       "show      0     0     0      0      0      0      0                 0   0   \n",
       "tells     0     0     0      0      0      0      0                 0   0   \n",
       "probe     0     0     0      0      0      0      0                 0   0   \n",
       "\n",
       "       21st  ...   hu  weekend  forever  calls  wife  sometimes  gr8  points  \\\n",
       "shop      0  ...    0        0        0      0     0          0    0       0   \n",
       "shot      0  ...    0        0        0      0     0          0    0       0   \n",
       "show      0  ...    0        0        0      0     1          0    0       0   \n",
       "tells     0  ...    0        0        0      0     0          0    0       0   \n",
       "probe     0  ...    0        0        0      0     0          0    0       1   \n",
       "\n",
       "       leak  personalised  \n",
       "shop      0             1  \n",
       "shot      0             0  \n",
       "show      0             0  \n",
       "tells     0             0  \n",
       "probe     1             0  \n",
       "\n",
       "[5 rows x 422 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "comatrix = occur_matrix.T.dot(occur_matrix)\n",
    "np.fill_diagonal(comatrix.values, 0)\n",
    "comatrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now, this matrix is incredibly sparse, and takes up space. By decomposing this matrix with Sigular Value Decomposition, we can find the K most significant words in the dataset and get the cooccurence matrix of only those words. This significantly reduces the size of the matrix but retains the K most connected words in the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([18.3012, 15.2739, 13.173, 12.5853, 12.3664, 10.9407, 10.3887, 10.307, 10.1774, 9.6903, 9.3421, 9.1932, 9.1603, 8.7779, 8.5957, 8.1919, 8.0, 8.0, 8.0, 8.0, 8.0, 7.5983, 7.4181, 7.2364, 7.154, 7.135, 6.7001, 6.6678, 6.4699, 6.2143, 6.0, 6.0, 6.0, 5.9453, 5.6071, 5.3588, 5.2166, 5.0, 5.0, 4.9969, 4.8505, 4.7946, 4.7653, 4.5803, 4.4092, 4.0996, 4.0, 3.6114, 3.5492, 3.3857, 3.2396, 3.2168, 3.1531, 3.0895, 3.0, 3.0, 2.6778, 2.6167, 2.595, 2.5607, 2.5315, 2.4984, 2.4765, 2.4457, 2.4024, 2.3381, 2.309, 2.2449, 2.0609, 2.0, 2.0, 2.0, 2.0, 2.0, 1.986, 1.9761, 1.9371, 1.9323, 1.8883, 1.8718, 1.8434, 1.8412, 1.827, 1.8101, 1.7929, 1.7869, 1.7644, 1.7531, 1.7464, 1.7138, 1.7128, 1.6824, 1.6397, 1.6175, 1.6039, 1.5866, 1.5809, 1.5602, 1.5396, 1.5056, 1.469, 1.3127, 1.1016, 1.0448, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "rows = spark.sparkContext.parallelize([DenseVector(row) for row in comatrix.values.tolist()])\n",
    "row_matrix = RowMatrix(rows)\n",
    "svd = row_matrix.computeSVD(len(comatrix.index)/2, computeU=True)  # reduce matrix by\n",
    "svd.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(os.environ['SPARK_HOME'] + \"/sbin/stop-all.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
